{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07638138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: load data (adjust path if needed)\n",
    "data_path = \"../mnt/data/laptop_data.csv\"   # notebook placed in notebooks/, so adjust relative path\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ba4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: clean / drop identifier columns\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Drop identifier-like columns (agar dataset me ho)\n",
    "for c in ['SKU','Model']:\n",
    "    if c in df.columns:\n",
    "        df = df.drop(columns=[c])\n",
    "\n",
    "print(\"After dropping identifiers, shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42109a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: target summary\n",
    "target = \"Price_INR\"\n",
    "print(\"Target exists:\", target in df.columns)\n",
    "display(df[target].describe())\n",
    "\n",
    "# Optional: sometimes price is skewed; log-transform helps for some models/plots\n",
    "df['log_price'] = np.log1p(df[target])\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df[target], kde=True)\n",
    "plt.title(\"Price_INR distribution\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['log_price'], kde=True)\n",
    "plt.title(\"log(1+Price_INR) distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: choose features (exclude target & newly created log)\n",
    "# Adjust this list based on columns present\n",
    "exclude = [target, 'log_price']\n",
    "features = [c for c in df.columns if c not in exclude]\n",
    "\n",
    "print(\"Candidate features:\", features)\n",
    "# Example small feature engineering: encode Touchscreen Yes/No -> 1/0 if present\n",
    "if 'Touchscreen' in df.columns:\n",
    "    df['Touchscreen_flag'] = df['Touchscreen'].astype(str).str.lower().map({'yes':1,'no':0}).fillna(0)\n",
    "    # replace in features\n",
    "    features = [f for f in features if f!='Touchscreen'] + ['Touchscreen_flag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: detect numeric and categorical features automatically\n",
    "num_cols = df[features].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = [c for c in features if c not in num_cols]\n",
    "\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: pipeline setup\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# train-test split\n",
    "X = df[features].copy()\n",
    "y = df['log_price']  # using log target improves stability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# full model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training model (this may take a moment)...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc997bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: evaluation on test set (report RMSE on original price scale)\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)   # inverse of log1p\n",
    "\n",
    "y_test_orig = np.expm1(y_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test_orig, y_pred, squared=False)\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "print(f\"RMSE (on original INR scale): {rmse:.2f}\")\n",
    "print(f\"R2 (on original INR scale): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: feature importances mapping back to original feature names\n",
    "# We need to get column names after ColumnTransformer\n",
    "preprocessor = model.named_steps['preprocessor']\n",
    "reg = model.named_steps['regressor']\n",
    "\n",
    "# get feature names produced by preprocessor\n",
    "try:\n",
    "    # sklearn >=1.0\n",
    "    num_features = num_cols\n",
    "    cat_features = preprocessor.named_transformers_['cat'].named_steps['ohe'].get_feature_names_out(cat_cols).tolist()\n",
    "    feature_names = num_features + cat_features\n",
    "except Exception as e:\n",
    "    # fallback: try older API or manual approach (less precise)\n",
    "    feature_names = num_cols + cat_cols  # approximate\n",
    "    print(\"Warning: couldn't expand categorical feature names precisely â€” using approximate names.\", e)\n",
    "\n",
    "importances = reg.feature_importances_\n",
    "# if shapes mismatch, truncate or pad (safe-guard)\n",
    "min_len = min(len(importances), len(feature_names))\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': feature_names[:min_len],\n",
    "    'importance': importances[:min_len]\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "display(feat_imp.head(30))\n",
    "\n",
    "# Plot top 20\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(data=feat_imp.head(20), x='importance', y='feature')\n",
    "plt.title(\"Top 20 Feature Importances (RandomForest on log_price)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: brand average price analysis (original price scale)\n",
    "if 'Brand' in df.columns:\n",
    "    brand_avg = df.groupby('Brand')['Price_INR'].agg(['count','mean','median']).reset_index()\n",
    "    brand_avg = brand_avg.sort_values('mean', ascending=False)\n",
    "    display(brand_avg.head(20))\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(data=brand_avg.head(15), x='Brand', y='mean')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Top 15 Brands by Average Price (mean)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'Brand' not present in dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: save results (feature importances and brand averages)\n",
    "out_dir = Path(\"../artifacts/analysis\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "feat_imp.to_csv(out_dir / \"feature_importances.csv\", index=False)\n",
    "if 'Brand' in df.columns:\n",
    "    brand_avg.to_csv(out_dir / \"brand_average_price.csv\", index=False)\n",
    "\n",
    "print(\"Saved feature_importances.csv and brand_average_price.csv in artifacts/analysis/\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
